{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **MNA - IAyAA**\n",
        "## **Actividad Complementaria no Evaluable : Titanic**\n",
        "## **Semanas 5 y 6**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "https://www.kaggle.com/datasets/yasserh/titanic-dataset"
      ],
      "metadata": {
        "id": "zozPejRcWme2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Datos reales de la tragedia del Titanic del 15 de abril de 1912:**\n",
        "\n",
        "*   Sobrevivió el 38% (706), Falleció el 62% (1517) de un total de 2223 pasajeros y tripulantes.\n",
        "*   Sobrevivientes:\n",
        "    * 1a clase: 62%\n",
        "    * 2a clase: 41%\n",
        "    * 3a clase: 25%\n",
        "    * Mujeres: 75%\n",
        "    * Niñ@s: 50%\n",
        "    * Hombres: 20%\n",
        "\n"
      ],
      "metadata": {
        "id": "Niw2W944ILsF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Te recomiendo revisar el Capítulo 2 del libro de la biblioteca digital Hands-on Machine Learning with Scikit-learn, Keras and TensorFlow, 3rd Edition, de Aurelien Geron, de la editorial O'Reilly. Es algo extenso, pero puedes ir leyéndolo en partes durante varias semanas, ya que tiene muchas sugerencias e ideas de cómo generar un buen modelo desde el inicio de la preparación de los datos, hasta llegar al modelo final.**\n",
        "\n",
        "https://biblioteca.tec.mx/inicio"
      ],
      "metadata": {
        "id": "3Rxn-oPkDLN3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4arRj0QkaK75"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "# Si queremos asegurar que en la partición los niveles de las categóricas queden estratificados lo mejor posible:\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "Q2MYJBBraPgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanicdata = sns.load_dataset('titanic')\n",
        "df = pd.DataFrame(titanicdata)   # por facilidad consideremos los datps como un DataFrame de Pandas.\n",
        "print(df.shape)\n",
        "df.head().T"
      ],
      "metadata": {
        "id": "-P-SKApxaRlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ver la siguiente liga para la identificación de los niveles \"deck\":\n",
        "\n",
        "https://clickamericana.com/wp-content/uploads/White-Star-Line-Titanic-and-Olympic.jpg"
      ],
      "metadata": {
        "id": "bc03JV6tDtFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['deck'].value_counts()"
      ],
      "metadata": {
        "id": "fVO1XfJ1BdLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a eliminar el factor \"deck\", pero visualicemos antes la cantidad de datos\n",
        "# perdidos que tiene:\n",
        "# Para reemplazar None con 'Missing':\n",
        "df['deck'] = df['deck'].cat.add_categories(['Missing']).fillna('Missing')\n",
        "\n",
        "# Podemos agrupar los datos por 'deck' y 'survived' y contar las ocurrencias:\n",
        "grouped = df.groupby(['deck', 'survived']).size().unstack()\n",
        "\n",
        "# Obtengamos un gráfico de pila:\n",
        "grouped.plot(kind='bar', stacked=True, colormap='viridis')\n",
        "\n",
        "plt.xlabel('Deck')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Stacked Bar Plot of Survival by Deck')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_LcvH5AoFiQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables con la misma información: \"survived\" y \"alive\"; \"pclass\" y \"class\"; \"embarked\" y \"embark_town\".\n",
        "\n",
        "### También eliminaremos por el momento la variable \"deck\".\n",
        "\n"
      ],
      "metadata": {
        "id": "h1vuBHj1Lcnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['alive','class','embark_town',\n",
        "         'deck'\n",
        "         ], axis=1, inplace=True)\n",
        "print(df.shape)\n",
        "df.head().T"
      ],
      "metadata": {
        "id": "XsqwVsVDKNXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **survived:** Sobrevive: No(0), Sí(1)\n",
        "*   **pclass:** Boleto clase: 1a,2a,3a\n",
        "*   **sex:** female, male\n",
        "*   **age:** Edad en años: 0.42 a 80\n",
        "*   **sibsp:** Número de herman@s, medios herman@s y espos@s: 0 a 8 sin ciertos niveles\n",
        "*   **parch:** Número de padres e hij@s a bordo, incluyendo hij@s adoptados: 0 a 6\n",
        "*   **fare:** Costo del boleto (libras): de \\$0 a \\$512.3\n",
        "*   **embarked:** Puerto de embarque: Cherbourg(C), Queenstown(Q), Southampton(S)\n",
        "*   **who:** Hombre, mujer, niñ@\n",
        "*   **adult_male:** Hombre adulto: Falso, Verdadero\n",
        "*   **alone:** Viaja solo: Falso, Verdadero\n"
      ],
      "metadata": {
        "id": "7t7tIwrCMlnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PREGUNTA:**\n",
        "\n",
        "## **¿Cómo se afecta el entrenamiento el usar por ejemplo una partición de 60%-20%-20% o una de 80%-10%-10%? ¿Cuándo se recomendaría usar una u otra de estas particiones?**\n"
      ],
      "metadata": {
        "id": "cBbHX5vx2VAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xtv, ytrain, ytv = train_test_split(df.iloc[:,1:], df.iloc[:,0],\n",
        "                                            train_size=0.6,\n",
        "                                            random_state=0\n",
        "                                            )\n",
        "Xval, Xtest, yval, ytest = train_test_split(Xtv, ytv,\n",
        "                                            train_size=0.5,\n",
        "                                            random_state=0\n",
        "                                            )\n",
        "\n",
        "print(Xtrain.shape, ytrain.shape)\n",
        "print(Xval.shape, yval.shape)\n",
        "print(Xtest.shape, ytest.shape)\n"
      ],
      "metadata": {
        "id": "N9-yGJWaciRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separemos variables numéricas y categóricas.\n",
        "# Supongamos que las separamos como se indica a continuación.\n",
        "\n",
        "cat_ord_lista = ['pclass']    # lista de las variables ordinales\n",
        "\n",
        "cat_nom_lista = ['sex','adult_male','embarked','who','alone']   # lista de variables nominales(& binarias)\n",
        "\n",
        "num_lista = ['age','sibsp','parch','fare']    # lista de las variables numéricas."
      ],
      "metadata": {
        "id": "BhEQDk7icnap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Análisis Variables Categóricas**"
      ],
      "metadata": {
        "id": "_GH_cuzJ4YZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Xtrain['pclass'].value_counts())\n",
        "print(Xtrain['pclass'].value_counts() / Xtrain.shape[0])"
      ],
      "metadata": {
        "id": "vfe-ICCqNxjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Xtrain['sex'].value_counts())\n",
        "print(Xtrain['sex'].value_counts() / Xtrain.shape[0])"
      ],
      "metadata": {
        "id": "dktOpKe54XNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Xtrain['adult_male'].value_counts())\n",
        "print(Xtrain['adult_male'].value_counts() / Xtrain.shape[0])"
      ],
      "metadata": {
        "id": "EvOnaw6y4hph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Xtrain['embarked'].value_counts())\n",
        "print(Xtrain['embarked'].value_counts() / Xtrain.shape[0])"
      ],
      "metadata": {
        "id": "l3ZfPSTYDnhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Xtrain['who'].value_counts())\n",
        "print(Xtrain['who'].value_counts() / Xtrain.shape[0])"
      ],
      "metadata": {
        "id": "hrqTJpzADncF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Xtrain['alone'].value_counts())\n",
        "print(Xtrain['alone'].value_counts() / Xtrain.shape[0])"
      ],
      "metadata": {
        "id": "J7vc-qxZOYtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Y la variable de salida:\n",
        "\n",
        "tmp = pd.DataFrame(yval)\n",
        "\n",
        "print(tmp.value_counts())\n",
        "print(tmp.value_counts() / tmp.shape[0])"
      ],
      "metadata": {
        "id": "Jd0nEigAYX1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PREGUNTA:**\n",
        "\n",
        "## **¿Qué transformaciones consideras serían adecuadas aplicar a las categóricas, de ser el caso?**"
      ],
      "metadata": {
        "id": "JRSawKK_6P77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Análisis Variables Numéricas**"
      ],
      "metadata": {
        "id": "9XAbtXJS5Fwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain[num_lista].hist();"
      ],
      "metadata": {
        "id": "8JiwDvuxDnXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain[num_lista].boxplot(vert=False);"
      ],
      "metadata": {
        "id": "jkkUVuM2O2Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PREGUNTA:**\n",
        "\n",
        "## **¿Qué transformaciones consideras serían adecuadas aplicar a las numéricas, de ser el caso?**"
      ],
      "metadata": {
        "id": "MvN79LbZ6jai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# variables numéricas:\n",
        "num_pipe = Pipeline(steps = [('impMediana', SimpleImputer(strategy='median')),\n",
        "                             ('minmax', MinMaxScaler())])\n",
        "num_pipe_nombres = num_lista\n",
        "\n",
        "\n",
        "# variables ordinales:\n",
        "catord_pipe = Pipeline(steps = [('impOrd', SimpleImputer(strategy='most_frequent')),\n",
        "                                ('ordtrasnf', OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1))])\n",
        "catord_pipe_nombres = cat_ord_lista\n",
        "\n",
        "\n",
        "#variables nominales y binarias:\n",
        "catnom_pipe = Pipeline(steps = [('impModa', SimpleImputer(strategy='most_frequent')),\n",
        "                             ('ohe', OneHotEncoder(drop='first', handle_unknown='ignore'))])\n",
        "catnom_pipe_nombres = cat_nom_lista\n",
        "\n",
        "\n",
        "columnasTransformer = ColumnTransformer(transformers = [('num_transf', num_pipe, num_pipe_nombres),\n",
        "                                                        ('catord_transf', catord_pipe, catord_pipe_nombres),\n",
        "                                                        ('catnom_transf', catnom_pipe, catnom_pipe_nombres)\n",
        "                                                        ],\n",
        "                                        remainder='passthrough')\n"
      ],
      "metadata": {
        "id": "F-pDuL5BDnTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conjuntamos conjunto de Entrenamiento y Validación para usar Cross-Validation:\n",
        "\n",
        "Xtrainval = pd.concat([Xtrain, Xval], axis=0)\n",
        "ytrainval = pd.concat([ytrain, yval], axis=0)\n",
        "\n",
        "print(Xtrainval.shape, ytrainval.shape)"
      ],
      "metadata": {
        "id": "53a6Rs3T6mFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **¿Por qué concatenamos estos conjuntos?**"
      ],
      "metadata": {
        "id": "pK7noTBDA-oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Podemos verifcar la cantidad de columnas nuevas que se estarán generando después\n",
        "# de aplicar las transformaciones (usualmente con lo que se llama ingeniería de\n",
        "# características podrían también agregarse más variables):\n",
        "\n",
        "Xtmp = Xtrainval.copy()\n",
        "tmp = columnasTransformer.fit_transform(Xtmp)\n",
        "\n",
        "print(\"Antes de las transformaciones:\", Xtmp.shape)\n",
        "print(\"Después de las transformaciones:\", tmp.shape)"
      ],
      "metadata": {
        "id": "qGld6zYQ6mCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependiendo del tipo de problema, deberás seleccionar las librerías de los\n",
        "# modelos correspondientes:\n",
        "\n",
        "# Modelos de Regresión:\n",
        "#from sklearn.linear_model import LinearRegression\n",
        "#from sklearn.neighbors import KNeighborsRegressor\n",
        "#from sklearn.tree import DecisionTreeRegressor\n",
        "#from sklearn.ensemble import RandomForestRegressor\n",
        "#from xgboost import XGBRegressor\n",
        "#from sklearn.neural_network import MLPRegressor\n",
        "#from sklearn.svm import SVR\n",
        "\n",
        "# Modelos de Claisficación:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import TomekLinks"
      ],
      "metadata": {
        "id": "mwrZBkknBlzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost-Clasificación:\n",
        "\n",
        "https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\n",
        "\n",
        "XGBost-Regresión:\n",
        "\n",
        "https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor\n",
        "\n",
        "\n",
        "Puedes consultar la lista de métricas en la siguiente liga:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html"
      ],
      "metadata": {
        "id": "QgP9XcG1aQvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PREGUNTA:**\n",
        "\n",
        "## **Ejecuta primeramente el modelo con sus hiperparámetros predeterminados y luego trata de ir razonando cómo y cuáles modificar.**\n",
        "\n",
        "## **En general con cada modelo se pueden aplicar también los métodos de GridSearchCV() o bien RandomizedSearchCV() de Scikit-learn para la búsqueda de los mejores hiperparámetros; pero por el momento hagámoslo de manera \"manual\" para tener una mejor comprensión del efecto de cada uno de dichos argumentos.**\n",
        "\n",
        "## **Para verificar que el modelo no esté sobreentrenado o subentrenado tendrás que monitorear de preferencia una métrica, la que consideres más importante. Sin embargo, no significa que las demás debas ignorarlas, sino que simplemente estarás haciendo el llamado ajuste de hiperparámetros, o ajuste fino (en inglés llamado fine-tuning) con respecto a tu métrica de mayor interés.**\n",
        "\n",
        "## **Antes de iniciar, ¿podríamos establecer un primer valor de entrada de la Exactitud (Accuracy) a partir del cual pudiéramos decir que el modelo está sub-entrenado? Indica qué valor tomarás como referencia en este problema para determinar que un modelo está sub-entrenado: ... [incluye aquí tu respuesta] ...**\n",
        "\n",
        "## **Y para el caso sobre-entrenado, ¿cuándo podríamos decir que el modelo está sobre-emntrenado? Indica qué criterio tomarás como referencia en este problema para determinar que un modelo está sobre-entrenado: ... [incluye aquí tu respuesta] ...**\n",
        "\n",
        "### En realidad el umbral para determinar cuándo se tiene un modelo sobreentrenado es relativo, pero en general se puede tomar siempre para iniciar que la diferencia entre entrenamiento y validación no sea mayor al 3% o 4%, en métricas de porcentaje."
      ],
      "metadata": {
        "id": "y_gECwMdg2gL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando versiones de XGBoost y Scikit-learn:\n",
        "\n",
        "import xgboost\n",
        "import sklearn\n",
        "\n",
        "print(\"Versiones al iniciar aquí:\")\n",
        "print(xgboost.__version__)\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "id": "G1cjsXFYJkdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Requerimos la versión 1.3.0 de Scikit-learn.\n",
        "# Una vez terminado de actualizar te pedirá que reinicies la sesión.\n",
        "# Reinicia, pero sin desconectar la sesión.\n",
        "!pip install scikit-learn==1.3.0"
      ],
      "metadata": {
        "id": "rkk3JFGLJrqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost\n",
        "import sklearn\n",
        "\n",
        "\n",
        "# Verifiquemos de nuevo las versiones:\n",
        "print(\"Versiones actualizadas:\")\n",
        "print(xgboost.__version__)\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "id": "TbbbtU7XKDVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veamos algunas variantes de los hiperparámetros de cada modelo\n",
        "# para que te familiarices con la manera en que afecta cada uno\n",
        "# de ellos en su desempeño:\n",
        "\n",
        "def modelos():\n",
        "  modelos, nombres = list(), list()\n",
        "\n",
        "\n",
        "\n",
        "  # Regresión Logística:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "  modelos.append(LogisticRegression(max_iter=100,    # 10, 100, 1000\n",
        "                                    C = 1.0,     # 0.000001, 0.005, 0.01,  1000\n",
        "                                    #random_state=1\n",
        "                                    ))\n",
        "  nombres.append('LR')\n",
        "\n",
        "\n",
        "\n",
        "  # k-Vecinos Más Cercanos:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "\n",
        "  modelos.append(KNeighborsClassifier(n_neighbors = 5,     # 1, 5, 21, 201\n",
        "                                      ))\n",
        "  nombres.append('kNN')\n",
        "\n",
        "\n",
        "\n",
        "  # Árbol de Decisión:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "\n",
        "  modelos.append(DecisionTreeClassifier(max_depth = None,       # None, 5, 3, 1\n",
        "                                        min_samples_split=2,   # 2,3,5, 20\n",
        "                                        #min_samples_leaf=1,  # trata al inicio de usar solo uno de estos, split o leaf, para su mejor comprensión.\n",
        "                                        #random_state=7\n",
        "                                        ))\n",
        "  nombres.append('DTree')\n",
        "\n",
        "\n",
        "\n",
        "  # Bosque Aleatorio:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "  modelos.append(RandomForestClassifier(n_estimators= 100,    # 100\n",
        "                                        max_depth= None,      # None, 1, 2,3, 4, 5, 6 ... ¿Se esperaría la misma profunidad en un RF y en un DT?\n",
        "                                        min_samples_split=2,    # 2, 5, 15\n",
        "                                        #random_state=0\n",
        "                                        ))\n",
        "  nombres.append('RF')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # XGBoost:\n",
        "  # https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\n",
        "  # https://xgboost.readthedocs.io/en/stable/parameter.html\n",
        "\n",
        "  modelos.append(XGBClassifier(booster= 'gbtree',\n",
        "                               n_estimators=100,   # A medida que se aumente \"n_estimators\", se debe disminuir el \"learning_rate\", de manera general.\n",
        "                               max_depth= 6,             # 1,3, 6,\n",
        "                               learning_rate=0.3,   #  0.3, 0.000001, 0.01, 100,     # participación o peso de cada árbol desde el inicio.\n",
        "                               subsample=1.0,        # 1.0,  0.9, 0.8, ... 0.5    # submuestreo con respecto a los renglones para evitar overfitting.\n",
        "                               #random_state=5,\n",
        "                               objective='binary:logistic',\n",
        "                               n_jobs=-1))\n",
        "  nombres.append('XGBoost')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Red Neuronal Artificial: Perceptrón MultiCapa:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
        "\n",
        "  modelos.append(MLPClassifier(hidden_layer_sizes=(30,),     # 100,  6, 24, 30, (15,15), (50,50)\n",
        "                               activation='logistic',\n",
        "                               max_iter=1000,                  # 200,\n",
        "                               alpha=0.0001,               # término de regularización L2.\n",
        "                               #learning_rate='constant',       # tasa de aprendizaje o tamaño de paso del método Gradiente Descendente.\n",
        "                               #learning_rate_init=0.001,\n",
        "                               #random_state=1\n",
        "                               ))\n",
        "  nombres.append('MLP')\n",
        "\n",
        "\n",
        "\n",
        "  # Máquina de Vector Soporte : Support Vector Machine\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "\n",
        "  modelos.append(SVC(kernel='rbf',\n",
        "                     C= 1.0,      # 1.0, 0.00001, 1000           # inversamente proporcional a la constante de regularización L2.\n",
        "                     gamma= 'scale',           # scale,  0.005\n",
        "                     #class_weight='balanced',     # Siempre puedes hacer uso del balanceo en caso de que ayude.\n",
        "                     #random_state=7\n",
        "                     ))\n",
        "  nombres.append('SVM')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return modelos, nombres\n",
        "\n",
        "\n",
        "\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "modelo, nombres = modelos()\n",
        "resultados = list()\n",
        "\n",
        "for i in range(len(modelo)):\n",
        "\n",
        "  # Definimos nuestro pipeline con las transformaciones y los modelos:\n",
        "  pipeline = Pipeline(steps=[('ct',columnasTransformer),('m',modelo[i])])\n",
        "\n",
        "  # Aplicaremos validación-cruzada:\n",
        "  micv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3)\n",
        "\n",
        "  # Definimos las métricas que desamos calcular dependiendo el tipo de problema.\n",
        "  # No tienes que incluir todas en cada problema, pero usemos varias a manera de ejemplo:\n",
        "  mismetricas = {'miacc':'accuracy',\n",
        "                 'mipre':'precision',\n",
        "                 'mirec':'recall',\n",
        "                 'mif1':'f1',\n",
        "                 'miroc':'roc_auc'}   # métricas de clasificación\n",
        "  \"\"\"\n",
        "  mismetricas = {'mimse':'neg_mean_squared_error',\n",
        "                 'mirmse':'neg_root_mean_squared_error',\n",
        "                 'mimape':'neg_mean_absolute_percentage_error',\n",
        "                 'mir2':'r2'}  # métricas de regresión\n",
        "  \"\"\"\n",
        "\n",
        "  # Llevamos a cabo el entrenamiento:\n",
        "  scores = cross_validate(pipeline,\n",
        "                          Xtrainval,\n",
        "                          ytrainval,\n",
        "                          scoring=mismetricas,\n",
        "                          cv=micv,\n",
        "                          return_train_score=True,\n",
        "                          )\n",
        "\n",
        "  # Guardemos el resultado de cada modelopara análisis posteriores.\n",
        "  resultados.append(scores)\n",
        "\n",
        "  # Desplegamos los valores de las métricas para verificar si no hay\n",
        "  # subentrenamiento o sobreentrenamiento:\n",
        "  print('>> %s' % nombres[i])\n",
        "  for j,k in enumerate(list(scores.keys())):\n",
        "    if j>1:\n",
        "      print('\\t %s %.3f (%.3f)' % (k, np.mean(scores[k]),np.std(scores[k])))  # también puedes usar nanmean y nanstd.\n",
        "\n"
      ],
      "metadata": {
        "id": "E0PjacenAFOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados   # aquí tienes toda la información generada durante el entrenamiento."
      ],
      "metadata": {
        "id": "g9ojnqWrLFNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En la lista de salida \"resultados\" está toda la información generada durante\n",
        "# el entrenamiento para cada métrica que se indicó. Dependiendo la métrica de\n",
        "# interés se puede seguir analizando, de preferencia el conjunto de validación o\n",
        "# prueba. Por ejemplo, hagamos un diagrama de caja para alguna de ellas:\n",
        "\n",
        "tmp = [resultados[j]['test_mipre'] for j in range(len(resultados)) ]\n",
        "\n",
        "plt.boxplot(tmp, labels=nombres, showmeans=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "24FIrWS9AFFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Mejor Modelo Final:**\n",
        "\n",
        "### **Supongamos que nuestra métrica de interés en este problema sea la precisión, ¿qué significa el valor de la precisión en el contexto del problema del Titanic?**\n",
        "\n",
        "Supongamos a continuación que el modelo de SVM tuvo el mejor desempeño con la métrica de Precision."
      ],
      "metadata": {
        "id": "KhC5Gnxi5OPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionemos los mismos valores de los hiperparámetros obtenidos previamente.\n",
        "# Sin embargo aquí podemos hacer una nueva búsqueda más detallada con algunos de\n",
        "# los métodos GridSearchCV() o RandomizedSearchCV() de sklearn, para tratar de\n",
        "# mejorar más el desempeño de este modelo.\n",
        "\n",
        "# Consulta la documentación respectiva:\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
        "\n",
        "# Supongamos que los siguientes valores de hiperparámetros son los mejores que encontramos,\n",
        "# entonces generemos ahora nuestro modelo final con el conjunto de prueba (Test) y\n",
        "# conjuntando los datos de Entrenamiento y Validación para que nuestro modelo pueda\n",
        "# en dado caso mejorar en lo que pueda, su desempeño:\n",
        "\n",
        "\n",
        "# Modelo Final:\n",
        "# Mejores hiperparámetros encontrados:\n",
        "mf = SVC(kernel='rbf', C= 1.0,gamma= 'scale')\n",
        "\n",
        "mf_pipe = Pipeline(steps=[('ct',columnasTransformer),('m',mf)])\n",
        "\n",
        "# Para este último modelo ajustamos por última vez con Train y Val:\n",
        "mf_pipe.fit(Xtrainval,ytrainval)\n",
        "\n",
        "\n",
        "# Y verificamos el desempeño con el conjunto de Prueba (Test):\n",
        "yhat = mf_pipe.predict(Xtest)\n",
        "\n",
        "print(classification_report(ytest, yhat))\n",
        "\n",
        "print('Métrica-ROC-Test:', np.round(roc_auc_score(ytest, yhat), 2))"
      ],
      "metadata": {
        "id": "ibRneJO92VBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# O bien, usando la matriz de confusión y calculando directamente cada métrica:\n",
        "\n",
        "cm = confusion_matrix(ytest, yhat)  # Con este acomodo, los renglones son los datos reales y las columnas las predicciones.\n",
        "cm"
      ],
      "metadata": {
        "id": "Bf5qiXIM6g-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VN = cm[0,0]\n",
        "VP = cm[1,1]\n",
        "FN = cm[1,0]\n",
        "FP = cm[0,1]\n",
        "\n",
        "# De aquí puedes obtener cualquiera de las métricas que desees.\n",
        "# Por ejemplo, la precisión, usando su fórmula:\n",
        "mi_precision = VP / (VP + FP)\n",
        "mi_precision"
      ],
      "metadata": {
        "id": "Xx7T1T156tyi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}