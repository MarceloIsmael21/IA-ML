{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wLK5tyC0afDk",
        "XmUZ46CwyEyu",
        "qmprVkJ_u56j",
        "a4Ka79ZTyM0_",
        "hLd2iTBMzZ93",
        "_wWlujaN0Zu-",
        "_MSXjy6i8qRD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## **Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
        "\n",
        "### Tecnológico de Monterrey\n",
        "\n",
        "### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## Adtividad de Semana 7\n",
        "\n",
        "### **Campañas publicitarias en redes sociales - Modelos de Regresión**\n"
      ],
      "metadata": {
        "id": "cCgXoRxlVFi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Nombre:**\n",
        "\n",
        "### **Matrícula:**"
      ],
      "metadata": {
        "id": "P2p9VQXDtFnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Trabajaremos con el archivo \"dataset_Facebook.csv\" que encuentras en la siguiente liga:**\n",
        "\n",
        "https://archive.ics.uci.edu/dataset/368/facebook+metrics\n",
        "\n",
        "### **Estos datos están asociados al siguiente artículo de Moro et.al. de ELSEVIER, que deberás descargar para contestar varias de las preguntas de esta actividad (el acceso es sin costo alguno):**\n",
        "\n",
        "https://www.semanticscholar.org/paper/Predicting-social-media-performance-metrics-and-of-Moro-Rita/dec55692590820754b53c916e29bb2b42c0e5104\n"
      ],
      "metadata": {
        "id": "EZ_5sfaamvHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **NOTA: No modifiques el código, salvo en las partes que se te indica.**"
      ],
      "metadata": {
        "id": "gOoOtosZ4bzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Puedes incluir más librerías, de ser necesario:\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder, FunctionTransformer\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "9MZs9gKJ1fWZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 1**\n"
      ],
      "metadata": {
        "id": "wLK5tyC0afDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Describe en qué consiste el método llamado de \"Curvas de Aprendizaje\" (Learning Cures), para monitorear el subentrenamiento o sobrbeentrenamiento de un modelo.**\n",
        "\n",
        "#### NOTA: Puedes apoyarte en la documentación de sklearn:\n",
        "\n",
        "https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py\n",
        "\n"
      ],
      "metadata": {
        "id": "VUaKQbUWxNYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto. +++++++++++"
      ],
      "metadata": {
        "id": "xBYkgkl5yDWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 2**"
      ],
      "metadata": {
        "id": "XmUZ46CwyEyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **De acuerdo al artículo de Moro et.al. de ELSEVIER, contesta las siguientes preguntas:**\n",
        "\n",
        "*   **a. ¿Cuál es el objetivo del problema que se plantea en el artículo?**\n"
      ],
      "metadata": {
        "id": "8pcpweI8aie8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto. +++++++++++"
      ],
      "metadata": {
        "id": "WIqvDWS4tFF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   **b. Describe a continuación el significado de cada una de las 8 variables con la cuales trabajaremos, de acuerdo a la información de las Tablas 2 y 3 del artículo de Moro et.al.**"
      ],
      "metadata": {
        "id": "DbSEBatds8Vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "\n",
        "*   Elemento de lista\n",
        "*   Elemento de lista\n",
        "\n",
        "etc ...\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto. +++++++++++"
      ],
      "metadata": {
        "id": "tHWhAUezdc-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **En esta actividad trabajarás solamente con el ajuste de modelos, por lo que la parte de procesamiento no la debes modificar. Solo haremos unos ajustes mínimos.**"
      ],
      "metadata": {
        "id": "N7aMmfvpWS2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los datos del archivo:\n",
        "\n",
        "data = pd.read_csv('dataset_Facebook.csv', sep=';', header='infer')\n",
        "print('Total de registros y variables:',data.shape)\n",
        "data.head(3).T"
      ],
      "metadata": {
        "id": "G8fYoeHruPu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 3**"
      ],
      "metadata": {
        "id": "qmprVkJ_u56j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Variables temporales**\n",
        "\n",
        "### **Recordemos que las varaibles temporales pueden tratarse como variables categóricas o numéricas, dependiendo del contexto. En nuestro caso las variables mes, día de la semana y hora en que se puso el post, podríamos considerarlas como variables categóricas ordinales. Sin embargo, para recordar cómo se transforman en cada uno de estos casos (numéricas y categóricas), consideraremos las variables de mes y día de la semana como categóricas ordinales y la variable hora como una variable cíclica.**\n",
        "\n",
        "### **En la Tabla 3 del artículo de ELSEVIER nos comentan que la variable Post_hour está etiquetada de 0 a 23, por lo que las 24 horas serían las 0 horas, es decir tiene un comportamiento cíclico de 24 horas, que en términos matemáticos se dice que es una variable cíclica módulo 24. Así, las 24 horas será equivalente a las 0 horas**\n",
        "\n",
        "### **La manera de transformar una variable T cíclica módulo M, es sustituyendo la columna original de la variable T por las siguientes dos columnas. Es lo que se llama ingeniería de características (feature engineering) dentro del área de ciencia de datos:**\n",
        "\n",
        "$Tsin = sin(2*\\pi*T/M)$\n",
        "\n",
        "$Tcos = cos(2*\\pi*T/M)$"
      ],
      "metadata": {
        "id": "flldXIo3uX6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NOTA: Donde se indica None, podrás agregar las líneas de código que consideres necesarias."
      ],
      "metadata": {
        "id": "joCe2SKLwl5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 3a:\n",
        "\n",
        "# Define las dos nuevas variables, \"horas_sin\" y \"horas_cos\" a partir de la\n",
        "# variable \"Post Hour\" y de acuerdo a como se indicó previamente:\n",
        "\n",
        "\n",
        "# ++++++++++++++ Incluye aquí tu código ++++++++++++++++++++++++++++++\n",
        "\n",
        "horas_sin = None\n",
        "horas_cos = None\n",
        "\n",
        "# +++++++++++++ Tesrmina sección de agregar código +++++++++++++++++++++"
      ],
      "metadata": {
        "id": "-HegyBexvaA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 3b:\n",
        "\n",
        "# Agrega estas dos nuevas variables al DataFrame de tus datos\n",
        "# y elimina la columna de la variable original \"Post Hour\":\n",
        "\n",
        "# ++++++++++++++ Incluye aquí tu código ++++++++++++++++++++++++++++++\n",
        "\n",
        "None\n",
        "\n",
        "# +++++++++++++ Termina sección de agregar código +++++++++++++++++++++\n",
        "\n",
        "\n",
        "# Veamos lo que tenemos hasta el momento:\n",
        "data.head(3).T"
      ],
      "metadata": {
        "id": "_q9bj6tZwi7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# De las Tablas 2 y 3 del artículo de ELSEVIER seleccionamos las variables que\n",
        "# trabajaremos en esta Actividad.\n",
        "\n",
        "# Separamos los datos de entrada (ver Tabla 3 del artículo) y de la variable de salida (ver Tabla 2):\n",
        "X = data[['Page total likes', 'Type', 'Category', 'Post Month', 'Post Weekday', 'Paid', 'horas_sin', 'horas_cos']]\n",
        "y = data[['Lifetime Post Consumers']]   # Hay 12 variables de salida, pero solo trabajaremos con la\n",
        "                                        # que se consideró la más importante en el artículo de ELSEVIER.\n",
        "\n",
        "\n",
        "# Particionamos en Train, Validation y Test en 70-15-15:\n",
        "Xtrain, Xtv, ytrain, ytv = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=7)\n",
        "Xval, Xtest, yval, ytest = train_test_split(Xtv, ytv, test_size=0.5, shuffle=True, random_state=7)\n",
        "\n",
        "\n",
        "print('Train:', Xtrain.shape, ytrain.shape)\n",
        "print('Val:', Xval.shape, yval.shape)\n",
        "print('Test:', Xtest.shape, ytest.shape)"
      ],
      "metadata": {
        "id": "N6m_XqcQnCHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain.describe(include='all').T   # Veamos alguna descripción como datos numéricos del conjunto de entrenamiento.\n",
        "                                   # En particular, las desviaciones estándar (std) desplegadas son las muestrales."
      ],
      "metadata": {
        "id": "7oog40NRzRSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ajuste variable categórica en Pipeline**\n",
        "\n",
        "#### **Veamos un ejemplo de cómo ajustar una variable categórica en la cual uno de sus niveles no tiene suficiente información, por ejemplo, que no tenga al menos un 5% de información cada nivel. Entonces reagruparemos los niveles más pequeños hasta obtener un 5% y esto mediante una función que podamos usar dentro del Pipeline, para evitar el filtrado de información.**"
      ],
      "metadata": {
        "id": "PLNnZzcczZzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtengamos las etiquetas únicas de data['Type'] ordenadas de mayor a menor frecuencia:\n",
        "Xtrain['Type'].unique()"
      ],
      "metadata": {
        "id": "bAIeoERKzY7E"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain['Type'].value_counts() / Xtrain.shape[0]   # Siguiendo la política de que cada nivel de una variable tenga\n",
        "                                                  # al menos el 5% de información, agruparemos los casos \"Link\"\n",
        "                                                  # y \"Video\" en un nuevo nivel que podría interpretarse como \"Otros\"."
      ],
      "metadata": {
        "id": "lXg9rSO8zxr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos la función que llevará a cabo esta transformación dentro del Pipeline:\n",
        "\n",
        "def mi_type(x):\n",
        "  x = x.values.ravel()  # Convertimos a un arreglo 1D\n",
        "  x = pd.Series(x, name='Type')  # seleccionamos la columna como datos tipo Series\n",
        "  x.loc[:] = x.map({'Photo':1, 'Status':2, 'Link':0, 'Video':0})  # Podrías etiquetarlos también como 3, en lugar de 0.\n",
        "  return x.values.reshape(-1, 1)    # Ajustamos la dimensión a un vector columna."
      ],
      "metadata": {
        "id": "szRedGTX0UwL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Transformación en la Variable de Salida**\n",
        "\n"
      ],
      "metadata": {
        "id": "VbrYu10q0lUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain.describe().T   # Información de la variable de salida."
      ],
      "metadata": {
        "id": "-T2adW4ElGQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observamos a continuación que hay un claro sesgo positivo en la variable de salida:\n",
        "ytrain.hist();"
      ],
      "metadata": {
        "id": "k-gb_Jwa0_6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrainlog = np.log(ytrain)   # Recordemos que nuestra variable de salida en un problema\n",
        "ytrainlog.hist();            # de Regresión se recomienda que esté aproximadamente\n",
        "                             # acampanada, por lo que la ajustaremos con el logaritmo\n",
        "                             # natural como primera aproximación."
      ],
      "metadata": {
        "id": "L9BvLilz1EfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para una primera aproximación, podemos decir que se ajusta de manera aceptable\n",
        "# la distribución con logaritmo a una acampanada.\n",
        "# Procedemos entonces de la misma manera con Val y Test:\n",
        "yvallog = np.log(yval)\n",
        "ytestlog = np.log(ytest)"
      ],
      "metadata": {
        "id": "B9Zm5VeA1EJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicaremos lo mínimo de transformaciones.\n",
        "# Las nuevas variables horas_sin y horas_cos ya están escaladas entre -1 y +1, por\n",
        "# lo que podemos dejarlas así y solamente cuidar sus posibles datos perdidos.\n",
        "\n",
        "num_pipe = Pipeline(steps = [('numImp', SimpleImputer(strategy='median')),\n",
        "                             ('scaler', MinMaxScaler())\n",
        "                             ])\n",
        "num_pipe_nombres = [0]   # ['Page total likes']  puedes indicar solamente el índice de la columna.\n",
        "\n",
        "\n",
        "# Las ordinales las identificamos como tales:\n",
        "ord_pipe = Pipeline(steps =  [('OrdImp', SimpleImputer(strategy='most_frequent')),\n",
        "                              ('Ordfun', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1 ))\n",
        "                              ])\n",
        "ord_pipe_nombres = [3,4]   # ['Post Month', 'Post Weekday']\n",
        "\n",
        "\n",
        "# Transformación del factor categórico de entrada \"Type\":\n",
        "catMap_pipe = Pipeline(steps = [('catMap', FunctionTransformer(mi_type))])\n",
        "catMap_pipe_nombres = ['Type']\n",
        "\n",
        "\n",
        "# Las nominales las transformamos con One-Hot-Encoder:\n",
        "nom_pipe = Pipeline(steps = [('NomImp', SimpleImputer(strategy='most_frequent')),\n",
        "                             ('ohe', OneHotEncoder(drop='first',\n",
        "                                                   handle_unknown='ignore',\n",
        "                                                   ))])\n",
        "nom_pipe_nombres = [1,2,5]  # ['Type', 'Category', 'Paid']\n",
        "\n",
        "\n",
        "# Variables numéricas con la hora:\n",
        "hora_pipe = Pipeline(steps = [('HoraImp', SimpleImputer(strategy='mean'))])\n",
        "hora_pipe_nombres = [6,7]   # ['horas_sin', 'horas_cos']\n",
        "\n",
        "\n",
        "# Conjuntamos las transformaciones que aplicaremos:\n",
        "columnasTransformer = ColumnTransformer(transformers = [('numpow', num_pipe, num_pipe_nombres),\n",
        "                                                        ('catOrd', ord_pipe, ord_pipe_nombres),\n",
        "                                                        ('catNom', nom_pipe, nom_pipe_nombres),\n",
        "                                                        ('catmap', catMap_pipe, catMap_pipe_nombres),\n",
        "                                                        ('hora', hora_pipe, hora_pipe_nombres)\n",
        "                                                        ],\n",
        "                                        remainder='passthrough')\n",
        "\n",
        "\n",
        "\n",
        "# Solo para saber la nueva cantidad de columnas después de las trasnformaciones:\n",
        "XtrainT = columnasTransformer.fit_transform(Xtrain)  # Ajustamos con Train...\n",
        "print('Variables de entrada original:', Xtrain.shape)\n",
        "print('Variables de entrada transformadas:', XtrainT.shape)"
      ],
      "metadata": {
        "id": "XGjwO1zq1JBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Criterio para determinar si un modelo está subentrenado en un problema de Regresión:**"
      ],
      "metadata": {
        "id": "LRzmwlys19dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Existen varios criterios para determinar si un modelo de regresión está\n",
        "# subentrenado, veamos a continuación unos de ellos.\n",
        "\n",
        "# El valor de RMSE-Root-Mean-Square-Error, se utiliza para medir el desempeño\n",
        "# mínimo que debiera obtener un modelo de regresión, es decir, este valor\n",
        "# se toma usualmente como el valor del modelo subentrenado y se compara generalmente\n",
        "# con el valor de la desviación estándar de la variable de salida, ya sea que la\n",
        "# estés tomando de manera original o con los datos transformados.\n",
        "# Veamos el valor de ambas:\n",
        "\n",
        "print('Desv-Est y-original: %.3f' % ytrain.values.std(ddof=1))        # Usemos la desviación estándar muestral\n",
        "print('Desv-Est y-logaritmo: %.3f' % ytrainlog.values.std(ddof=1))    # ajustando los grados de libertad."
      ],
      "metadata": {
        "id": "yPTioK_D2z9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Recordemos que la desviación estándar está en las mismas unidades de la variable original, por lo que en este caso tendríamos que la desviación estándar nos habla de aproximadamente 771 personas que dieron click en alguna parte del post.**\n",
        "\n",
        "#### **En esta activiad estaremos comparando los errores en términos del logaritmo de la variable de salida, por lo que nuestro valor de referencia será el valor que obtienes en Desv_Est y_logaritmo=0.916 (aproximadamente). Así, los errores RMSE de los valores de predicción y los reales de los modelos que estarás obteniendo, deberán ser menores a este valor para no considerarlos subentrenados.**"
      ],
      "metadata": {
        "id": "VX9eaf782cLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **NOTA sobre los grados de libertad ddof (delta degree of freedom):**\n",
        "\n",
        "Ver documentación: https://numpy.org/doc/stable/reference/generated/numpy.std.html\n",
        "\n",
        "#### **Estricamente, desde el punto de vista matemático las desviaciones estándar que uno calcula deben ser las muestrales, es decir, std(ddof=1). Sin embargo, en la práctica es muy común usar la función con su valor predeterminado que es ddof=0 y que se traduce a calcular la desviación estándar poblacional. Repito, en la práctica suele pasarse por alto este ajuste porque cuando se tienen datos de miles o más regitros, la diferencia entre el resultado problacional y el muestral es mínima. En esta actividad lo pongo solamente para recordarlo y en dado caso cuando tengas menos de 100 registros sí hacer este ajuste, porque la diferencia entre ambos ya podría ser importante.**"
      ],
      "metadata": {
        "id": "Qa0DX0zFJYx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Como se va a utilizar Validación-Cruzada, concatenamos los conjuntos de entrenamiento y validación\n",
        "# en uno nuevo conjunto aumentado que llamaremos trainval para utilizar como entrenamiento:\n",
        "\n",
        "Xtrainval = pd.concat([Xtrain, Xval], axis=0)\n",
        "ytrainvallog = pd.concat([ytrainlog, yvallog], axis=0)"
      ],
      "metadata": {
        "id": "zccFM5f2F3Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 4**\n"
      ],
      "metadata": {
        "id": "a4Ka79ZTyM0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 4a.\n",
        "\n",
        "# Al ejecutar las siguientes líneas de código determina si el modelo de\n",
        "# Bosque Aleatorio con sus valores de hiperparámetros predeterminadas está\n",
        "# Subentrenado o Sobreentrenado. De ser así, busca los valores de sus\n",
        "# hiperparámetros que consideres más adecuados para que ya no\n",
        "# esté sub-o-sobreentrenado:\n",
        "\n",
        "\n",
        "# ++++++++++++++ Incluye aquí tu código ++++++++++++++++++++++++++++++\n",
        "\n",
        "elmodelo_RF = RandomForestRegressor()\n",
        "\n",
        "# +++++++++++++ Tesrmina sección de agregar código +++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "mipipe = Pipeline(steps=[('ct',columnasTransformer),('m', elmodelo_RF)])\n",
        "\n",
        "train_sizes, train_scores, val_scores = learning_curve(estimator=mipipe,\n",
        "                                                        X=Xtrainval,\n",
        "                                                        y=np.ravel(ytrainvallog),\n",
        "                                                        cv=5,\n",
        "                                                        train_sizes= np.linspace(0.1, 1.0, 10),\n",
        "                                                        scoring= 'neg_mean_squared_error',  # error MSE\n",
        "                                                        n_jobs=-1)\n",
        "\n",
        "\n",
        "\n",
        "# Calculamos los promedios y desviación estándar de entrenamiento para RMSE,\n",
        "# como tenemos los de MSE, debemos obtener su raíz cuadrada. El negativo es porque\n",
        "# sklearn nos devuelve en realidad el negativo del Error Cuadrático Medio MSE:\n",
        "\n",
        "rmse_train_scores = np.sqrt(-train_scores)\n",
        "rmse_val_scores = np.sqrt(-val_scores)\n",
        "\n",
        "train_mean = np.mean(rmse_train_scores, axis=1)\n",
        "train_std = np.std(rmse_train_scores, axis=1, ddof=1)   # aquí también hacemos el ajuste de la desviación estándar muestral.\n",
        "val_mean = np.mean(rmse_val_scores, axis=1)\n",
        "val_std = np.std(rmse_val_scores, axis=1, ddof=1)\n",
        "\n",
        "\n",
        "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training RMSE')\n",
        "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
        "\n",
        "plt.plot(train_sizes, val_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation RMSE')\n",
        "plt.fill_between(train_sizes, val_mean + val_std, val_mean - val_std, alpha=0.15, color='green')\n",
        "\n",
        "plt.title('Curvas de Aprendizaje (Learning Curves)')\n",
        "plt.xlabel('Tamaño de la muestra de entrenamiento')\n",
        "plt.ylabel('Error RMSE')\n",
        "plt.grid()\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oXpqwlS6lnSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 4b.\n",
        "\n",
        "# Una vez que verifiques que no está sobreentrenado o subentrenado el modelo,\n",
        "# podemos calcular el RMSE del mejor ajuste con los datos de Prueba.\n",
        "# Incluye los valores de tus mejores hiperparámetros encontrados del RandomForest:\n",
        "\n",
        "# ++++++++++++++ Incluye aquí tus ajustes ++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "elmodelo_RF = RandomForestRegressor()\n",
        "\n",
        "\n",
        "\n",
        "# +++++++++++++ Tesrmina sección de realizar ajustes +++++++++++++++++++++\n",
        "\n",
        "\n",
        "mipipe = Pipeline(steps=[('ct',columnasTransformer),('m', elmodelo_RF)])\n",
        "mipipe.fit(pd.DataFrame(Xtrainval, columns=Xtrain.columns), np.ravel(ytrainvallog))\n",
        "yhattest_RF = mipipe.predict(Xtest)\n",
        "\n",
        "print('Error RSME(Test) de Random Forest: %.3f' % np.sqrt(mean_squared_error(np.ravel(ytestlog), yhattest_RF)))"
      ],
      "metadata": {
        "id": "5yEGf3-ft3cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 5**"
      ],
      "metadata": {
        "id": "HKwEq8z-zS7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Repite el mismo proceso del Ejercicio 4 anterior para obtener los hiperparámetros que nos lleven a casos de modelos no subentrenados o sobreentrenados, en cada uno de los siguientes casos:**\n",
        "\n",
        "*   **a. Extreme Gradient Boost XGBoost**\n",
        "*   **b. Máquina de Vector Soporte SVM**\n",
        "*   **c. Red Neuronal Perceptrón Multicapa MLP**"
      ],
      "metadata": {
        "id": "hLd2iTBMzZ93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Incluye a continuación las celdas y líneas de código que consideres necesarias\n",
        "# para responder el Ejercicio 5a, 5b y 5c.\n",
        "\n",
        "\n",
        "None\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uIuE5qYYvhkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 6**"
      ],
      "metadata": {
        "id": "_wWlujaN0Zu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importancia de características**\n",
        "\n",
        "#### **Ejercicio 6a.**\n",
        "\n",
        "*   **Con base al mejor modelo encontrado, realiza una análisis de importancia de características con el conjunto de prueba (Test).**\n",
        "\n",
        "*   **Obtener un diagrama de cajas o algún tipo de visualización para mostrar estos resultados.**\n",
        "\n",
        "\n",
        "#### **Ejercicio 6b.**\n",
        "\n",
        "*   **Con base a los gráficos obtenidos indica cuáles son los tres factores más importantes y que dan mayor información para la predicción de la variable de salida.**\n",
        "\n",
        "*  **Compara tus resultados con el resultado de la Figura 6 del artículo de ELSEVIER. Indica tus coincidencias y diferencias.**"
      ],
      "metadata": {
        "id": "KE2SlAmy8xsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++ Incluye aquí tu código +++++++++++++++++++++++++++++++\n",
        "# Ejercicio 6a.\n",
        "\n",
        "\n",
        "None\n",
        "\n",
        "\n",
        "\n",
        "# +++++++++++++ Termina sección de agregar código +++++++++++++++++++++"
      ],
      "metadata": {
        "id": "tzmrvjYd_apk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "### **Ejercicio 6b**\n",
        "\n",
        "None\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto. +++++++++++"
      ],
      "metadata": {
        "id": "p8Z1OpmZ9ZDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 7**"
      ],
      "metadata": {
        "id": "_MSXjy6i8qRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Incluye tus conclusiones finales de la Actividad.**"
      ],
      "metadata": {
        "id": "A01wHjjM0eNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "\n",
        "None\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto. +++++++++++"
      ],
      "metadata": {
        "id": "aeZrOQkU0x9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">> **Fin de la Actividad de la Semana 7**"
      ],
      "metadata": {
        "id": "6r0YHMtI0ypO"
      }
    }
  ]
}